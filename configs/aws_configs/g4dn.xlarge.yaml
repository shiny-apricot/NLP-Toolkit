instance_type: "g4dn.xlarge"

compute:
  num_cpus: 4
  memory_gb: 16
  num_gpus: 1
  cuda_visible_devices: "0"
  torch_num_threads: 4

training:
  batch_size: 8  # Good balance for T4 GPU
  gradient_accumulation_steps: 4
  fp16: true  # T4 has good fp16 support
  num_workers: 2
  max_length: 512
  cache_dir: "cache"

model:
  model_type: "bart"
  model_name: "facebook/bart-base"  # Good balance of speed/quality
  dtype: "float16"  # T4 performs well with float16

aws:
  region: "us-west-2"  # Usually has good availability
  s3_bucket: "my-summarization-model-bucket"
  sagemaker_role_arn: "arn:aws:iam::your-account-id:role/service-role/AmazonSageMaker-ExecutionRole"
  cloudwatch:
    log_group: "/aws/summarization/gpu"
    log_stream: "g4dn-training"

logging:
  level: "INFO"
  log_dir: "./logs"
  tensorboard_dir: "./logs/tensorboard"
  cloudwatch_enabled: true

monitoring:
  enable_wandb: false
  enable_memory_tracking: true
  log_interval_steps: 100
  gpu_memory_alerts: true
  memory_threshold_percent: 85

security:
  enable_iam_auth: true
  use_aws_ssm: true
  ssm_parameter_path: "/summarization/gpu/"
  encrypt_outputs: true

development:
  debug_mode: false
  profile_code: true
  disable_tqdm: false
  enable_gpu_optimizations: true
  torch_compile: true  # Works well on T4

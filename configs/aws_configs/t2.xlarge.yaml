instance_type: "t2.xlarge"

compute:
  num_cpus: 4
  memory_gb: 16
  num_gpus: 0
  cuda_visible_devices: ""
  torch_num_threads: 4

training:
  batch_size: 4
  gradient_accumulation_steps: 8
  fp16: false
  num_workers: 2
  max_length: 512
  cache_dir: "cache"

model:
  model_type: "bart"
  model_name: "facebook/bart-base"  # Using smaller model for CPU
  dtype: "float32"  # CPU doesn't benefit from bfloat16

aws:
  region: "us-west-2"
  s3_bucket: "my-summarization-model-bucket"
  sagemaker_role_arn: "arn:aws:iam::your-account-id:role/service-role/AmazonSageMaker-ExecutionRole"
  cloudwatch:
    log_group: "/aws/summarization/cpu"
    log_stream: "t2-xlarge-training"

logging:
  level: "INFO"
  log_dir: "./logs"
  tensorboard_dir: "./logs/tensorboard"
  cloudwatch_enabled: true

monitoring:
  enable_wandb: false
  enable_memory_tracking: true
  log_interval_steps: 100
  cpu_usage_alerts: true
  memory_threshold_percent: 85

security:
  enable_iam_auth: true
  use_aws_ssm: true
  ssm_parameter_path: "/summarization/cpu/"
  encrypt_outputs: true

development:
  debug_mode: false
  profile_code: true
  disable_tqdm: true  # Better for logging in CPU environments
  enable_cpu_optimizations: true
  torch_compile: false  # CPU-specific setting